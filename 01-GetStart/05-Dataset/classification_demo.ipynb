{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aead5e36",
   "metadata": {},
   "source": [
    "## Step1 导入相关包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9cea20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'\n",
    "from transformers import AutoTokenizer,AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644b4873",
   "metadata": {},
   "source": [
    "## Step2 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1ff5a84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'review'],\n",
       "    num_rows: 7766\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# data = pd.read_csv('ChnSentiCorp_htl_all.csv')\n",
    "# data\n",
    "from datasets import *\n",
    "data = load_dataset('csv',data_files='./ChnSentiCorp_htl_all.csv',split=\"train\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43a3bbc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1d0db8fc08a4ae5ada058dde9c63527",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/7766 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'review'],\n",
       "    num_rows: 7765\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = data.dropna()\n",
    "# data\n",
    "data = data.filter(lambda x: x['review'] is not None)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31cd71b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['距离川沙公路较近,但是公交指示不对,如果是\"蔡陆线\"的话,会非常麻烦.建议用别的路线.房间较为简单.',\n",
       " '商务大床房，房间很大，床有2M宽，整体感觉经济实惠不错!',\n",
       " '早餐太差，无论去多少人，那边也不加食品的。酒店应该重视一下这个问题了。房间本身很好。']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"review\"][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c687df78",
   "metadata": {},
   "source": [
    "## Step3 创建Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15ed6b1",
   "metadata": {},
   "source": [
    "## Step4 划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b1b1569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'review'],\n",
       "        num_rows: 6988\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'review'],\n",
       "        num_rows: 777\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from torch.utils.data import random_split\n",
    "\n",
    "# trainset,validset = random_split(dataset,lengths=[0.9,0.1])\n",
    "# len(trainset),len(validset)\n",
    "data = data.train_test_split(test_size=0.1)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6f9474",
   "metadata": {},
   "source": [
    "## Step5 创建DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eda004c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"hfl/rbt3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd1edc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_fun(examples):\n",
    "    tokenizer_e = tokenizer(examples[\"review\"],max_length=128,truncation=True)\n",
    "    tokenizer_e[\"labels\"] = examples['label']\n",
    "    return tokenizer_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9aaa0b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_data = data.map(process_fun,batched=True,remove_columns=data[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1fca5884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 777\n",
       "})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_data_train = tokenizer_data['train']\n",
    "tokenizer_data_test = tokenizer_data['test']\n",
    "tokenizer_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5c33c0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "51ce8e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8961b2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "# trainloader = DataLoader(data[\"train\"],batch_size=32,shuffle=True,collate_fn=collate_func)\n",
    "# valiloader = DataLoader(data[\"test\"],batch_size=64,shuffle=False,collate_fn=collate_func)\n",
    "trainloader = DataLoader(tokenizer_data_train,batch_size=32,shuffle=True,collate_fn=collator)\n",
    "valiloader = DataLoader(tokenizer_data_test,batch_size=64,shuffle=False,collate_fn=collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3dfc06bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7fa2b2f81b80>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "02ad42e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 3341, 7270,  ...,    0,    0,    0],\n",
       "        [ 101, 1765, 4415,  ...,  749, 2990,  102],\n",
       "        [ 101, 2456, 6379,  ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [ 101, 5018,  753,  ...,    0,    0,    0],\n",
       "        [ 101,  122,  119,  ...,    0,    0,    0],\n",
       "        [ 101, 2595,  817,  ...,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "        1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1,\n",
       "        1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0])}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(enumerate(valiloader))[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3286911",
   "metadata": {},
   "source": [
    "## Step6 创建模型及优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c8a68d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at hfl/rbt3 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"hfl/rbt3\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ab0a7af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x7fa2b2d086d0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "53c7b167",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(),lr=2e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5575145",
   "metadata": {},
   "source": [
    "## Step7 训练与验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7da2e1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d6588bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    model.eval()\n",
    "    acc_num = 0\n",
    "    with torch.inference_mode():\n",
    "        for batch in valiloader:\n",
    "            if torch.cuda.is_available():\n",
    "                batch = {k:v.cuda() for k,v in batch.items()}\n",
    "            output = model(**batch)\n",
    "            pred = torch.argmax(output.logits,dim=-1)\n",
    "            acc_num += (pred.long() == batch['labels'].long()).float().sum()\n",
    "    return acc_num / tokenizer_data_test.num_rows\n",
    "\n",
    "def train(epoch=3,log_step=100):\n",
    "    global_step = 0\n",
    "    for ep in range(epoch):\n",
    "        model.train()\n",
    "        for batch in trainloader:\n",
    "            if torch.cuda.is_available():\n",
    "                batch = {k:v.cuda() for k,v in batch.items()}\n",
    "            optimizer.zero_grad()\n",
    "            output = model(**batch)\n",
    "            output.loss.backward()\n",
    "            optimizer.step()\n",
    "            if global_step % log_step ==0:\n",
    "                print(f\"ep:{ep}, global_step:{global_step}, loss:{output.loss.item()}\")\n",
    "            global_step += 1\n",
    "        acc = evaluate()\n",
    "        print(f\"e:{ep}, acc:{acc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efee819",
   "metadata": {},
   "source": [
    "## Step8 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b16baf13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "777"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_data_test.num_rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e5022db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep:0, global_step:0, loss:0.06920930743217468\n",
      "ep:0, global_step:100, loss:0.07966431230306625\n",
      "ep:0, global_step:200, loss:0.002455147448927164\n",
      "e:0, acc:0.8803088665008545\n",
      "ep:1, global_step:300, loss:0.010180889628827572\n",
      "ep:1, global_step:400, loss:0.00998788420110941\n",
      "e:1, acc:0.8764479160308838\n",
      "ep:2, global_step:500, loss:0.0695374384522438\n",
      "ep:2, global_step:600, loss:0.0030672855209559202\n",
      "e:2, acc:0.8828828930854797\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4e580e",
   "metadata": {},
   "source": [
    "## Step9 模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1e5e1bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入：我觉得这家酒店中等偏差，其中隔音效果不好！，模型预测结果：差评！\n"
     ]
    }
   ],
   "source": [
    "sen = '我觉得这家酒店中等偏差，其中隔音效果不好！'\n",
    "id2_lable = {0:'差评！',1:'好评！'}\n",
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    input = tokenizer(sen,return_tensors='pt')\n",
    "    input = {k:v.cuda() for k,v in input.items()}\n",
    "    output = model(**input)\n",
    "    pred = torch.argmax(output.logits,dim=-1)\n",
    "    print(f\"输入：{sen}，模型预测结果：{id2_lable.get(pred.item())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "53b70ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "# model.config.id2label\n",
    "model.config.id2label = id2_lable\n",
    "pipe = pipeline(\"text-classification\",model=model,tokenizer=tokenizer,device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d95386a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': '差评！', 'score': 0.9614468216896057}]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(sen) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
